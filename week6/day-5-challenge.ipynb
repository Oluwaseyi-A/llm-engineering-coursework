{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "936713d0-e7ff-43da-9e44-dfd302538389",
   "metadata": {},
   "source": [
    "## The AI Product Pricer\n",
    "\n",
    "A model that can estimate how much something costs, from its description.\n",
    "\n",
    "The dataset is here:  \n",
    "https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023\n",
    "\n",
    "And the folder with all the product datasets is here:  \n",
    "https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023/tree/main/raw/meta_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68123949-d7c5-4721-8f28-a8bec3d109be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Optimized Fine-tuning Code for Price Estimation\n",
    "Key improvements:\n",
    "1. Better data preparation and validation\n",
    "2. Improved system and user prompts\n",
    "3. Optimized hyperparameters\n",
    "4. Enhanced training data diversity\n",
    "5. Better evaluation metrics\n",
    "\"\"\"\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import json\n",
    "import random\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import Counter, defaultdict\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "\n",
    "load_dotenv(override=True)\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')\n",
    "os.environ['ANTHROPIC_API_KEY'] = os.getenv('ANTHROPIC_API_KEY', 'your-key-if-not-using-env')\n",
    "os.environ['HF_TOKEN'] = os.getenv('HF_TOKEN', 'your-key-if-not-using-env')\n",
    "\n",
    "hf_token = os.environ['HF_TOKEN']\n",
    "login(hf_token, add_to_git_credential=True)\n",
    "\n",
    "from items import Item\n",
    "from testing import Tester\n",
    "\n",
    "openai = OpenAI()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "with open('train.pkl', 'rb') as file:\n",
    "    train = pickle.load(file)\n",
    "\n",
    "with open('test.pkl', 'rb') as file:\n",
    "    test = pickle.load(file)\n",
    "\n",
    "# OPTIMIZATION 1: Better data selection and stratification\n",
    "def analyze_price_distribution(items):\n",
    "    \"\"\"Analyze price distribution to ensure balanced training\"\"\"\n",
    "    prices = [item.price for item in items]\n",
    "    price_ranges = {\n",
    "        'low': [p for p in prices if p < 25],\n",
    "        'medium': [p for p in prices if 25 <= p < 100],\n",
    "        'high': [p for p in prices if 100 <= p < 500],\n",
    "        'very_high': [p for p in prices if p >= 500]\n",
    "    }\n",
    "    \n",
    "    print(\"Price Distribution Analysis:\")\n",
    "    for range_name, price_list in price_ranges.items():\n",
    "        print(f\"{range_name}: {len(price_list)} items (${min(price_list):.2f} - ${max(price_list):.2f})\")\n",
    "    \n",
    "    return price_ranges\n",
    "\n",
    "def stratified_sampling(items, n_samples, seed=42):\n",
    "    \"\"\"Create stratified sample to ensure balanced price representation\"\"\"\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # Group items by price ranges\n",
    "    price_groups = defaultdict(list)\n",
    "    for item in items:\n",
    "        if item.price < 25:\n",
    "            price_groups['low'].append(item)\n",
    "        elif item.price < 100:\n",
    "            price_groups['medium'].append(item)\n",
    "        elif item.price < 500:\n",
    "            price_groups['high'].append(item)\n",
    "        else:\n",
    "            price_groups['very_high'].append(item)\n",
    "    \n",
    "    # Sample proportionally from each group\n",
    "    total_items = len(items)\n",
    "    sampled_items = []\n",
    "    \n",
    "    for group_name, group_items in price_groups.items():\n",
    "        group_proportion = len(group_items) / total_items\n",
    "        group_samples = max(1, int(n_samples * group_proportion))  # At least 1 from each group\n",
    "        \n",
    "        if len(group_items) >= group_samples:\n",
    "            sampled_items.extend(random.sample(group_items, group_samples))\n",
    "        else:\n",
    "            sampled_items.extend(group_items)\n",
    "    \n",
    "    # If we haven't reached target, sample remaining from largest groups\n",
    "    while len(sampled_items) < n_samples:\n",
    "        largest_group = max(price_groups.values(), key=len)\n",
    "        remaining_items = [item for item in largest_group if item not in sampled_items]\n",
    "        if remaining_items:\n",
    "            sampled_items.append(random.choice(remaining_items))\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return sampled_items[:n_samples]\n",
    "\n",
    "# Analyze distribution\n",
    "analyze_price_distribution(train)\n",
    "\n",
    "# OPTIMIZATION 2: Improved data selection\n",
    "# Use stratified sampling for better representation\n",
    "fine_tune_train = stratified_sampling(train, 10000)  # Increased from 200\n",
    "fine_tune_validation = stratified_sampling(train[10000:], 100)  # Increased from 50\n",
    "\n",
    "print(f\"\\nTraining set: {len(fine_tune_train)} items\")\n",
    "print(f\"Validation set: {len(fine_tune_validation)} items\")\n",
    "\n",
    "# OPTIMIZATION 3: Enhanced prompts with better instructions\n",
    "def messages_for_training(item):\n",
    "    \"\"\"Improved system prompt and user prompt for training\"\"\"\n",
    "    system_message = \"\"\"You are an expert price estimator with deep knowledge of retail markets, product categories, and pricing patterns. \n",
    "\n",
    "Your task is to estimate the retail price of items based on their descriptions, features, and specifications. Consider factors like:\n",
    "- Product category and market positioning\n",
    "- Brand reputation and quality indicators\n",
    "- Features, specifications, and complexity\n",
    "- Materials and build quality\n",
    "- Target market and use case\n",
    "\n",
    "Provide only the price in the format \"Price is $X.XX\" where X.XX is your estimate rounded to the nearest cent. Be precise and realistic in your pricing.\"\"\"\n",
    "    \n",
    "    # Enhanced user prompt with better context\n",
    "    user_prompt = item.test_prompt().replace(\" to the nearest dollar\", \"\").replace(\"\\n\\nPrice is $\", \"\")\n",
    "    user_prompt = f\"Please estimate the retail price for this item:\\n\\n{user_prompt.strip()}\"\n",
    "    \n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "        {\"role\": \"assistant\", \"content\": f\"Price is ${item.price:.2f}\"}\n",
    "    ]\n",
    "\n",
    "def messages_for_inference(item):\n",
    "    \"\"\"Consistent prompt format for inference\"\"\"\n",
    "    system_message = \"\"\"You are an expert price estimator with deep knowledge of retail markets, product categories, and pricing patterns. \n",
    "\n",
    "Your task is to estimate the retail price of items based on their descriptions, features, and specifications. Consider factors like:\n",
    "- Product category and market positioning\n",
    "- Brand reputation and quality indicators\n",
    "- Features, specifications, and complexity\n",
    "- Materials and build quality\n",
    "- Target market and use case\n",
    "\n",
    "Provide only the price in the format \"Price is $X.XX\" where X.XX is your estimate rounded to the nearest cent. Be precise and realistic in your pricing.\"\"\"\n",
    "    \n",
    "    user_prompt = item.test_prompt().replace(\" to the nearest dollar\", \"\").replace(\"\\n\\nPrice is $\", \"\")\n",
    "    user_prompt = f\"Please estimate the retail price for this item:\\n\\n{user_prompt.strip()}\"\n",
    "    \n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72018edf-60b4-474e-aa57-2b9108e89f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_for_training(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443cb03e-5b56-49b3-9b91-de6e556673cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_for_inference(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9039584-777e-4453-81b4-ea7d65579060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIMIZATION 4: Data quality validation\n",
    "def validate_training_data(items):\n",
    "    \"\"\"Validate training data quality\"\"\"\n",
    "    valid_items = []\n",
    "    issues = []\n",
    "    \n",
    "    for i, item in enumerate(items):\n",
    "        # Check for reasonable price ranges\n",
    "        if item.price <= 0:\n",
    "            issues.append(f\"Item {i}: Invalid price ${item.price}\")\n",
    "            continue\n",
    "        \n",
    "        # Check for minimum content length\n",
    "        prompt = item.test_prompt()\n",
    "        if len(prompt.strip()) < 50:\n",
    "            issues.append(f\"Item {i}: Prompt too short ({len(prompt)} chars)\")\n",
    "            continue\n",
    "            \n",
    "        # Check for reasonable token count\n",
    "        if hasattr(item, 'token_count') and item.token_count < 20:\n",
    "            issues.append(f\"Item {i}: Too few tokens ({item.token_count})\")\n",
    "            continue\n",
    "            \n",
    "        valid_items.append(item)\n",
    "    \n",
    "    print(f\"Data validation: {len(valid_items)}/{len(items)} items valid\")\n",
    "    if issues:\n",
    "        print(f\"Issues found: {len(issues)}\")\n",
    "        for issue in issues[:5]:  # Show first 5 issues\n",
    "            print(f\"  {issue}\")\n",
    "    \n",
    "    return valid_items\n",
    "\n",
    "# Validate data\n",
    "fine_tune_train = validate_training_data(fine_tune_train)\n",
    "fine_tune_validation = validate_training_data(fine_tune_validation)\n",
    "\n",
    "def make_jsonl(items, for_training=True):\n",
    "    \"\"\"Create JSONL with improved error handling\"\"\"\n",
    "    result = \"\"\n",
    "    for item in items:\n",
    "        try:\n",
    "            if for_training:\n",
    "                messages = messages_for_training(item)\n",
    "            else:\n",
    "                messages = messages_for_inference(item)\n",
    "            \n",
    "            messages_str = json.dumps(messages, ensure_ascii=False)\n",
    "            result += '{\"messages\": ' + messages_str +'}\\n'\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing item {item}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return result.strip()\n",
    "\n",
    "def write_jsonl(items, filename, for_training=True):\n",
    "    \"\"\"Write JSONL with UTF-8 encoding\"\"\"\n",
    "    with open(filename, \"w\", encoding='utf-8') as f:\n",
    "        jsonl = make_jsonl(items, for_training)\n",
    "        f.write(jsonl)\n",
    "\n",
    "# Write training files\n",
    "write_jsonl(fine_tune_train, \"fine_tune_train.jsonl\", for_training=True)\n",
    "write_jsonl(fine_tune_validation, \"fine_tune_validation.jsonl\", for_training=True)\n",
    "\n",
    "# Upload files\n",
    "with open(\"fine_tune_train.jsonl\", \"rb\") as f:\n",
    "    train_file = openai.files.create(file=f, purpose=\"fine-tune\")\n",
    "\n",
    "with open(\"fine_tune_validation.jsonl\", \"rb\") as f:\n",
    "    validation_file = openai.files.create(file=f, purpose=\"fine-tune\")\n",
    "\n",
    "# OPTIMIZATION 5: Better hyperparameters\n",
    "wandb_integration = {\"type\": \"wandb\", \"wandb\": {\"project\": \"gpt-pricer-optimized\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fde744-2957-4e0f-a08b-a848c7fb59b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved hyperparameters\n",
    "fine_tuning_job = openai.fine_tuning.jobs.create(\n",
    "    training_file=train_file.id,\n",
    "    validation_file=validation_file.id,\n",
    "    model=\"gpt-4o-mini-2024-07-18\",\n",
    "    seed=42,\n",
    "    hyperparameters={\n",
    "        \"n_epochs\": 3,  # Increased from 1 - more epochs for better learning\n",
    "        \"batch_size\": 4,  # Smaller batch size for more stable training\n",
    "        \"learning_rate_multiplier\": 0.5  # Lower learning rate for stability\n",
    "    },\n",
    "    integrations=[wandb_integration],\n",
    "    suffix=\"pricer-v2\"\n",
    ")\n",
    "\n",
    "print(f\"Fine-tuning job created: {fine_tuning_job.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df60820-e457-4fc1-989f-65ca9d42bb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor training\n",
    "def monitor_training(job_id, max_checks=50):\n",
    "    \"\"\"Monitor training progress\"\"\"\n",
    "    import time\n",
    "    \n",
    "    for i in range(max_checks):\n",
    "        job = openai.fine_tuning.jobs.retrieve(job_id)\n",
    "        print(f\"Status: {job.status}\")\n",
    "        \n",
    "        if job.status == \"succeeded\":\n",
    "            print(f\"Training completed! Model: {job.fine_tuned_model}\")\n",
    "            return job.fine_tuned_model\n",
    "        elif job.status == \"failed\":\n",
    "            print(\"Training failed!\")\n",
    "            return None\n",
    "        \n",
    "        time.sleep(60)  # Check every minute\n",
    "    \n",
    "    return None\n",
    "\n",
    "# OPTIMIZATION 6: Improved inference function\n",
    "def get_price_improved(s):\n",
    "    \"\"\"Enhanced price extraction with better error handling\"\"\"\n",
    "    if not s:\n",
    "        return 0.0\n",
    "    \n",
    "    # Remove common prefixes and clean up\n",
    "    s = s.replace('Price is $', '').replace('$', '').replace(',', '').strip()\n",
    "    \n",
    "    # Try multiple regex patterns\n",
    "    patterns = [\n",
    "        r\"(\\d+\\.?\\d*)\",  # Basic number\n",
    "        r\"(\\d{1,4}(?:,\\d{3})*(?:\\.\\d{2})?)\",  # Currency format\n",
    "        r\"[-+]?\\d*\\.?\\d+\",  # Scientific notation\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, s)\n",
    "        if match:\n",
    "            try:\n",
    "                return float(match.group(1) if match.groups() else match.group())\n",
    "            except ValueError:\n",
    "                continue\n",
    "    \n",
    "    return 0.0\n",
    "\n",
    "def gpt_fine_tuned_improved(item, model_name):\n",
    "    \"\"\"Improved inference with better error handling and consistency\"\"\"\n",
    "    try:\n",
    "        messages = messages_for_inference(item)\n",
    "        \n",
    "        response = openai.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=messages,\n",
    "            seed=42,\n",
    "            max_tokens=20,  # Increased from 7\n",
    "            temperature=0.1,  # Low temperature for consistency\n",
    "            top_p=0.9\n",
    "        )\n",
    "        \n",
    "        reply = response.choices[0].message.content\n",
    "        price = get_price_improved(reply)\n",
    "        \n",
    "        # Sanity check - reject unrealistic prices\n",
    "        if price < 0.01 or price > 50000:\n",
    "            print(f\"Warning: Unusual price prediction: ${price:.2f} for {item.title[:50]}...\")\n",
    "        \n",
    "        return price\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error predicting price for {item.title[:50]}: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "# OPTIMIZATION 7: Enhanced evaluation\n",
    "def evaluate_model_comprehensive(predictor, test_data, model_name=\"Fine-tuned Model\"):\n",
    "    \"\"\"Comprehensive model evaluation with multiple metrics\"\"\"\n",
    "    print(f\"\\n=== Evaluating {model_name} ===\")\n",
    "    \n",
    "    # Run standard test\n",
    "    tester = Tester(predictor, test_data, title=model_name)\n",
    "    tester.run()\n",
    "    \n",
    "    # Additional analysis\n",
    "    errors = tester.errors\n",
    "    truths = tester.truths\n",
    "    guesses = tester.guesses\n",
    "    \n",
    "    # Price range analysis\n",
    "    price_ranges = {\n",
    "        'low': [(t, g, e) for t, g, e in zip(truths, guesses, errors) if t < 25],\n",
    "        'medium': [(t, g, e) for t, g, e in zip(truths, guesses, errors) if 25 <= t < 100],\n",
    "        'high': [(t, g, e) for t, g, e in zip(truths, guesses, errors) if 100 <= t < 500],\n",
    "        'very_high': [(t, g, e) for t, g, e in zip(truths, guesses, errors) if t >= 500]\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n=== Performance by Price Range ===\")\n",
    "    for range_name, data in price_ranges.items():\n",
    "        if data:\n",
    "            range_errors = [e for _, _, e in data]\n",
    "            range_truths = [t for t, _, _ in data]\n",
    "            avg_error = np.mean(range_errors)\n",
    "            mape = np.mean([e/t for t, _, e in data if t > 0]) * 100\n",
    "            print(f\"{range_name.upper()}: {len(data)} items, Avg Error: ${avg_error:.2f}, MAPE: {mape:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eda817f-bc19-4efa-9c36-cfeab6c2060d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for training to complete and then test\n",
    "# You'll need to replace this with your actual fine-tuned model name\n",
    "fine_tuned_model_name = monitor_training(fine_tuning_job.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cea8d19-2e85-4111-94ab-fb83b4955f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When ready to test:\n",
    "if fine_tuned_model_name:\n",
    "    test_predictor = lambda item: gpt_fine_tuned_improved(item, fine_tuned_model_name)\n",
    "    evaluate_model_comprehensive(test_predictor, test[:250], \"Optimized Fine-tuned Model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
